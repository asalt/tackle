from __future__ import annotations

import os
import textwrap
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Iterable, Optional

import pandas as pd

from .utils import read_config


@dataclass(frozen=True)
class ConfigSummary:
    analysis_name: str
    total_samples: int
    metadata_columns: list[str]
    recommended_design_columns: list[str]
    lines: list[str]


def _as_str(value) -> str:
    if value is None:
        return ""
    return str(value)


def summarize_config(conf_path: str, *, max_values: int = 12) -> ConfigSummary:
    config = read_config(conf_path)
    conf_df = pd.DataFrame.from_dict(config).T

    total = len(conf_df)
    analysis_name = Path(conf_path).stem

    meta_cols = ("recno", "runno", "searchno", "label")
    metadata_columns = sorted([
        c for c in conf_df.columns if c not in meta_cols and not str(c).startswith("__")
    ])

    value_counts = {col: int(conf_df[col].nunique(dropna=True)) for col in metadata_columns}
    value_count_df = pd.Series(value_counts).to_frame("count")
    value_count_df["ratio"] = value_count_df["count"] / max(total, 1)

    recommended = (
        value_count_df.query("ratio < 1 & ratio > 1/@total")
        .sort_values(by="ratio", ascending=False)
        .index.astype(str)
        .tolist()
    )

    lines: list[str] = []
    lines.append(f"# Config: {conf_path}")
    lines.append(f"# Samples: {total}")
    if not metadata_columns:
        lines.append("# No metadata columns detected beyond recno/runno/searchno/label.")
        return ConfigSummary(
            analysis_name=analysis_name,
            total_samples=total,
            metadata_columns=[],
            recommended_design_columns=[],
            lines=lines,
        )

    lines.append("# Metadata columns (unique values):")
    for col in metadata_columns:
        nunique = int(conf_df[col].nunique(dropna=True))
        if nunique == 0:
            lines.append(f"# - {col}: 0")
            continue
        if nunique > max_values:
            lines.append(f"# - {col}: {nunique}")
            continue
        values = (
            conf_df[col]
            .dropna()
            .astype(str)
            .drop_duplicates()
            .sort_values()
            .tolist()
        )
        preview = ", ".join(values)
        lines.append(f"# - {col}: {nunique} ({preview})")

    if recommended:
        lines.append("# Recommended design columns (good for --formula):")
        for col in recommended:
            lines.append(f"# - {col}")

    return ConfigSummary(
        analysis_name=analysis_name,
        total_samples=total,
        metadata_columns=[str(c) for c in metadata_columns],
        recommended_design_columns=recommended,
        lines=lines,
    )


def render_tacklerun_skeleton(
    *,
    conf_path: str,
    name: Optional[str] = None,
    result_dir: str = "./results",
    data_dir: str = "./data/e2g/",
    file_formats: Iterable[str] = (".png", ".pdf"),
    non_zeros: str = "1",
    normalization_flag: str = "--median",
    only_load_local: bool = False,
) -> str:
    summary = summarize_config(conf_path)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    suggested_design = summary.recommended_design_columns[0] if summary.recommended_design_columns else "group"
    file_format_flags = "\n".join(f"    --file-format {fmt}" for fmt in file_formats)
    only_local_flag = "    --only-load-local" if only_load_local else "    # --only-load-local"

    name_default = name or f'{summary.analysis_name}_$(date +%Y%m%d)'

    script = f"""\
#!/usr/bin/env bash
set -euo pipefail

# Generated by: tackle make-run
# Generated at: {now}
#
# This is a runnable skeleton. Search for "TODO:" to customize.
#
# Tip: Avoid `eval`. Use bash arrays + `\"${{cmd[@]}}\"` to keep quoting safe.

CONF="{conf_path}"   # TODO: set path to your .conf if you move this script

# Results land in: $RESULT_DIR/<config_basename_without_ext>/$NAME/
RESULT_DIR="{result_dir}"   # TODO: base results directory
DATA_DIR="{data_dir}"       # TODO: location of e2g files
NAME="{name_default}"       # TODO: analysis name (subfolder under results)

# Pick a design column for volcano formulas (recommended columns listed below).
DESIGN_COL="{suggested_design}"   # TODO: e.g. group, treat, batch

{os.linesep.join(summary.lines)}

HEADMAIN=(
    --name "$NAME"
    --result-dir "$RESULT_DIR"
    --data-dir "$DATA_DIR"
{file_format_flags}
    {normalization_flag}
    --non-zeros {non_zeros}
    # --nonzero-subgroup "$DESIGN_COL"
{only_local_flag}
    # --group "$DESIGN_COL"   # only for simple 2-group volcano; can block formula-based designs
)

# ---- Volcano settings ----
VOLCANO_FOLDCHANGE=2
VOLCANO_NUMBER_BY="pValue"
VOLCANO_LABEL_SCALE=1.8
VOLCANO_FORMULA="~ 0 + $DESIGN_COL"

# Use a heredoc so you can paste multi-line contrast definitions safely.
# TODO: fill these in. Prefer named contrasts:
#   MyContrast = treatA - treatB,
read -r -d '' VOLCANO_CONTRASTS <<'EOF'
EOF

run_volcano() {{
    tackle "${{HEADMAIN[@]}}" "$CONF" \\
        volcano \\
        --fill-na-zero \\
        --impute-missing-values \\
        --number-by "$VOLCANO_NUMBER_BY" \\
        --foldchange "$VOLCANO_FOLDCHANGE" \\
        --formula "$VOLCANO_FORMULA" \\
        --contrasts "$VOLCANO_CONTRASTS" \\
        --label-scale "$VOLCANO_LABEL_SCALE"
}}

run_export_and_metrics() {{
    tackle "${{HEADMAIN[@]}}" "$CONF" \\
        export --level gct \\
        metrics
}}

main() {{
    # TODO: uncomment what you want.
    # run_export_and_metrics
    # run_volcano
    :
}}

main "$@"
"""
    return textwrap.dedent(script)


def render_cluster2_sweep_skeleton(
    *,
    conf_path: str,
    name: Optional[str] = None,
    result_dir: str = "./results",
    data_dir: str = "./data/e2g/",
    file_formats: Iterable[str] = (".png",),
    non_zeros: str = "1",
    normalization_flag: str = "--median",
    only_load_local: bool = False,
    k_start: int = 3,
    k_end: int = 30,
) -> str:
    summary = summarize_config(conf_path)
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    file_format_flags = "\n".join(f"    --file-format {fmt}" for fmt in file_formats)
    only_local_flag = "    --only-load-local" if only_load_local else "    # --only-load-local"

    name_default = name or f'{summary.analysis_name}_cluster2_$(date +%Y%m%d)'

    script = f"""\
#!/usr/bin/env bash
set -euo pipefail

# Generated by: tackle make-cluster
# Generated at: {now}
#
# This is a runnable skeleton for sweeping cluster2 k-means/PAM over a k range.
# Search for "TODO:" to customize.

CONF="{conf_path}"   # TODO: set path to your .conf if you move this script

# Results land in: $RESULT_DIR/<config_basename_without_ext>/$NAME/
RESULT_DIR="{result_dir}"   # TODO: base results directory
DATA_DIR="{data_dir}"       # TODO: location of e2g files
NAME="{name_default}"       # TODO: analysis name (subfolder under results)

# Optional: speed up reruns when iterating by caching data load/normalization.
export TACKLE_CACHE=1
# export TACKLE_CACHE_DIR="./.tackle_cache"
# export TACKLE_CACHE_BUST=""

# Optional: write clustering results to a per-analysis SQLite DB for browsing (Shiny-friendly).
export TACKLE_CLUSTER_DB=1
# export TACKLE_CLUSTER_DB_PATH=""

{os.linesep.join(summary.lines)}

HEADMAIN=(
    --name "$NAME"
    --result-dir "$RESULT_DIR"
    --data-dir "$DATA_DIR"
{file_format_flags}
    {normalization_flag}
    --non-zeros {non_zeros}
{only_local_flag}
)

# Typical k sweep: 3..30 (often a good final k is ~7..14 for gene clustering).
K_START={k_start}
K_END={k_end}

CLUSTER_FUNCS=(kmeans)       # TODO: add PAM if desired: (kmeans PAM)
FILLNA_METHODS=(min)         # TODO: add avg to treat missing as ~0 for zscores

Z_SCORE="0"                  # TODO: "0" for z-score, "None" for raw log values
Z_SCORE_BY=""                # TODO: e.g. sampletype; leave empty for none
SEED=1234

run_cluster2_sweep() {{
    for FUNC in "${{CLUSTER_FUNCS[@]}}"; do
        for FILLNA in "${{FILLNA_METHODS[@]}}"; do
            for K in $(seq "$K_START" "$K_END"); do
                echo "cluster2: func=$FUNC fillna=$FILLNA k=$K" >&2
                tackle "${{HEADMAIN[@]}}" "$CONF" \\
                    cluster2 \\
                    --cluster-db \\
                    --cluster-func "$FUNC" \\
                    --nclusters "$K" \\
                    --cluster-fillna "$FILLNA" \\
                    --z-score "$Z_SCORE" \\
                    --seed "$SEED" \\
                    ${{Z_SCORE_BY:+--z-score-by "$Z_SCORE_BY"}}
            done
        done
    done
}}

summarize_cluster2() {{
    local analysis_name
    analysis_name="$(basename "${{CONF%.conf}}")"
    local base="$RESULT_DIR/$analysis_name/$NAME"

    mapfile -d '' tsvs < <(find "$base" -path "*/clustermap/*" -name "*.tsv" -print0)
    if (( ${{#tsvs[@]}} == 0 )); then
        echo "No cluster TSVs found under: $base" >&2
        return 1
    fi

    tackle cluster-summary "${{tsvs[@]}}" \\
        --out "$base/cluster2_runs.tsv" \\
        --per-cluster-out "$base/cluster2_clusters.tsv"

    echo "Wrote:" >&2
    echo "  $base/cluster2_runs.tsv" >&2
    echo "  $base/cluster2_clusters.tsv" >&2
}}

plot_cluster() {{
    local cluster_file="$1"
    local cluster_id="$2"

    tackle "${{HEADMAIN[@]}}" "$CONF" \\
        cluster2 \\
        --cluster-file "$cluster_file" "$cluster_id"
}}

main() {{
    # TODO: uncomment what you want.
    # run_cluster2_sweep
    # summarize_cluster2
    :
}}

main "$@"
"""
    return textwrap.dedent(script)


def write_script(path: str, content: str, *, force: bool = False) -> str:
    out_path = Path(path)
    if out_path.exists() and not force:
        raise FileExistsError(f"{out_path} already exists (use --force to overwrite)")
    out_path.write_text(content)
    try:
        mode = out_path.stat().st_mode
        out_path.chmod(mode | 0o111)
    except OSError:
        pass
    return str(out_path)
